{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Huco2sgMaJX"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "from scipy.stats import pearsonr\n",
        "from statsmodels.stats.multitest import multipletests\n",
        "\n",
        "# Generate random RDMs\n",
        "np.random.seed(42)\n",
        "\n",
        "num_neural_rdms = 4\n",
        "num_dnn_rdms = 7\n",
        "\n",
        "rdm_size = 1870\n",
        "\n",
        "neural_rdms = [np.random.rand(rdm_size, rdm_size) for _ in range(num_neural_rdms)]\n",
        "\n",
        "dnn_rdms = [np.random.rand(rdm_size, rdm_size) for _ in range(num_dnn_rdms)]\n",
        "\n",
        "# Apply PCA to reduce dimensionality\n",
        "reduced_neural_rdms = []\n",
        "for neural_rdm in neural_rdms:\n",
        "    scaler = StandardScaler()\n",
        "    neural_rdm_scaled = scaler.fit_transform(neural_rdm)\n",
        "\n",
        "    pca_model = PCA(n_components=100)\n",
        "    pca_model.fit(neural_rdm_scaled)\n",
        "\n",
        "    reduced_neural_rdm = pca_model.transform(neural_rdm_scaled)\n",
        "    reduced_neural_rdms.append(reduced_neural_rdm)\n",
        "\n",
        "reduced_dnn_rdms = []\n",
        "for dnn_rdm in dnn_rdms:\n",
        "    scaler = StandardScaler()\n",
        "    dnn_rdm_scaled = scaler.fit_transform(dnn_rdm)\n",
        "\n",
        "    pca_model = PCA(n_components=100)\n",
        "    pca_model.fit(dnn_rdm_scaled)\n",
        "\n",
        "    reduced_dnn_rdm = pca_model.transform(dnn_rdm_scaled)\n",
        "    reduced_dnn_rdms.append(reduced_dnn_rdm)\n",
        "\n",
        "# Correlation between reduced neural and DNN RDMs\n",
        "correlations = np.zeros((num_neural_rdms, num_dnn_rdms))\n",
        "p_values = []\n",
        "\n",
        "for i in range(num_neural_rdms):\n",
        "    for j in range(num_dnn_rdms):\n",
        "        reduced_neural_i = reduced_neural_rdms[i]\n",
        "        reduced_dnn_j = reduced_dnn_rdms[j]\n",
        "\n",
        "        # Calculate Pearson correlation coefficient\n",
        "        correlation, p_value = pearsonr(reduced_neural_i.flatten(), reduced_dnn_j.flatten())\n",
        "        correlations[i, j] = correlation\n",
        "        p_values.append(p_value)\n",
        "\n",
        "print(\"\\nCorrelation matrix between reduced Neural and DNN RDMs:\\n\", correlations)\n",
        "print(\"\\np-values for Pairwise Hypothesis Test:\\n\", p_values)\n",
        "\n",
        "# Visualize the correlation matrix with heatmap\n",
        "sns.heatmap(correlations, annot=True, cmap=\"coolwarm\", fmt=\".2f\", vmin=-1, vmax=1)\n",
        "plt.title(\"Correlation Matrix between Reduced Neural and DNN RDMs\")\n",
        "plt.show()\n",
        "\n",
        "# Multiple testing correction using Benjamini-Hochberg procedure\n",
        "reject, corrected_p_values, _, _ = multipletests(p_values, method='fdr_bh')\n",
        "\n",
        "print(\"\\nResults for Pairwise Hypothesis Test (Benjamini-Hochberg Correction):\\n\")\n",
        "for i in range(num_neural_rdms):\n",
        "    for j in range(num_dnn_rdms):\n",
        "        correlation = correlations[i, j]\n",
        "        p_value = corrected_p_values[i * num_dnn_rdms + j]\n",
        "        is_rejected = reject[i * num_dnn_rdms + j]\n",
        "\n",
        "        print(f\"NN layer {i + 1} vs. DNN layer {j + 1}: correlation={correlation:.3f}, p-value={p_value:.3f}, rejected={is_rejected}\")\n"
      ]
    }
  ]
}